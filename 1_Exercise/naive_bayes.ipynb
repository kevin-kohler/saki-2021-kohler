{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0d188549868dd9b57c79410266c16c0a520d2a7d56fddc347ee11b41cf39d63b9",
   "display_name": "Python 3.8.5 32-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "d188549868dd9b57c79410266c16c0a520d2a7d56fddc347ee11b41cf39d63b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from stop_words import get_stop_words\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "### GridSearchCV for parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data, pick relevant columns and concatenate them to a single string\n",
    "data = pd.read_csv(\"transaction_data.csv\", sep = \";\", index_col = 0)\n",
    "X = data[[\"Buchungstext\", \"Verwendungszweck\", \"Beguenstigter_Zahlungspflichtiger\", \"Betrag\"]].agg(\" \".join, axis=1)\n",
    "y = data[[\"Label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training & test set (X: features, e.g. \"Verwendungszweck\" / y: label to be predicted)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, random_state = 2021)"
   ]
  },
  {
   "source": [
    "# Apply vectorization and TF IDF transformation\n",
    "vect = TfidfVectorizer(stop_words = get_stop_words(\"german\"), ngram_range = (1,3))\n",
    "vect.fit(X_train)\n",
    "X_train_count = vect.transform(X_train)\n",
    "X_test_count = vect.transform(X_test)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 119,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "metadata": {},
     "execution_count": 120
    }
   ],
   "source": [
    "# Implement model and train it\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_count, y_train.values.ravel())"
   ]
  },
  {
   "source": [
    "# Test predictive quality of multinomial Naive Bayes classifier on test data and display quality indicator accuracy\n",
    "#y_predict = model.predict(X_test_count)\n",
    "#accuracy_rating = accuracy_score(y_test, y_predict)\n",
    "#print(\"Accuracy score: \" + str(accuracy_rating))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 121,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement pipeline to prevent data leakage and cross-validate parameters\n",
    "pipe = Pipeline([\n",
    "    (\"vect\", TfidfVectorizer(stop_words = get_stop_words(\"german\"), ngram_range = (1,3))),\n",
    "    (\"model\", MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                  precision    recall  f1-score   support\n\n         finance       1.00      1.00      1.00         8\n          income       1.00      1.00      1.00         5\n         leisure       0.90      1.00      0.95        26\n          living       1.00      0.40      0.57         5\n         private       1.00      0.80      0.89         5\nstandardOfLiving       0.93      1.00      0.97        14\n\n        accuracy                           0.94        63\n       macro avg       0.97      0.87      0.90        63\n    weighted avg       0.94      0.94      0.93        63\n\n"
     ]
    }
   ],
   "source": [
    "# Test predictive quality of multinomial Naive Bayes classifier on test data and display quality indicators\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cross-validated accuracy score: 0.9\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation for more generalisable results\n",
    "cross_val = cross_val_score(pipe, X, y.values.ravel(), cv = 10).mean()\n",
    "print(\"Cross-validated accuracy score: \" + str(cross_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'pivot'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-163-98264f9185bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Print confusion matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcf_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcf_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcf_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Predicted\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Reference\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcf_matrix\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcf_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\".2%\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlight_palette\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"seagreen\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_cmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'pivot'"
     ]
    }
   ],
   "source": [
    "# Print confusion matrix\n",
    "cf_matrix = confusion_matrix(y_test, y_predict)\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot = True, fmt = \".2%\", cmap = sns.light_palette(\"seagreen\", as_cmap = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}