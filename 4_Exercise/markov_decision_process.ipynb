{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# import necessary packages & libraries\n",
    "import mdptoolbox\n",
    "from itertools import product\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# create table containing all potential permutations of actions, fields, item colours and item placings\n",
    "def state_table():\n",
    "    \n",
    "    # states can be constituted in the form of an array containing field position, action (store/restore) and colour\n",
    "    options_actions = 2\n",
    "    number_fields = 4\n",
    "    options_colors = 3\n",
    "    options_placings = 4\n",
    "\n",
    "    # create array of potential state permutations (1.536 x 6 [4x fields, 1x action, 1x colour])\n",
    "    permutations = np.ndarray(shape=(options_actions*options_colors*(options_placings**number_fields), number_fields+2))\n",
    "\n",
    "    # create list of potential field states (iterate over the different placing options per each single field)\n",
    "    field_states = list(product(np.arange(options_placings), repeat=number_fields))\n",
    "\n",
    "    for field_states_count, field_state in enumerate(field_states):\n",
    "        for actions_count in range(options_actions):\n",
    "            for colours_count in range(options_colors):\n",
    "                # Index states\n",
    "                state_indices = options_actions * options_colors * field_states_count + actions_count * options_colors + colours_count\n",
    "                \n",
    "                # Perform colours count shifting\n",
    "                permutations[state_indices, :] = *field_state, colours_count, actions_count\n",
    "\n",
    "    return permutations\n",
    "\n",
    "states = state_table()\n",
    "states[:3]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 2., 0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def trans_prob(states):\n",
    "\n",
    "    options_actions = 2\n",
    "    number_fields = 4\n",
    "    options_colors = 3\n",
    "    options_placings = 4\n",
    "    n_states = states.shape[0]\n",
    "\n",
    "    # return array of given shape and type filled with zeros\n",
    "    # number_fields + 1 due to start/stop field\n",
    "    trans = np.zeros((number_fields + 1, n_states, n_states))\n",
    "\n",
    "    for state1 in range(n_states):\n",
    "        for field in range(number_fields):\n",
    "            for state2 in range(n_states):\n",
    "                first_st = states[state1]\n",
    "                second_st = states[state2]\n",
    "\n",
    "                number_action = first_st[-2]\n",
    "                number_column = second_st[-1]\n",
    "\n",
    "                # in this case: put/store object\n",
    "                if number_action == 0:\n",
    "                    if first_st[field] == 3 and second_st[field] == number_column:\n",
    "                        trans[field, state1, state2] = 1\n",
    "                    else:\n",
    "                        trans[4, state1, state2] = 1\n",
    "                # in this case: pick/restore object\n",
    "                else:\n",
    "                    if first_st[field] == number_column and second_st[field] == 3:\n",
    "                        trans[field, state1, state2] = 1\n",
    "                    else:\n",
    "                        trans[4, state1, state2] = 1\n",
    "\n",
    "            row_sum = np.sum(trans[field, state1, :])\n",
    "            # values are subject to division assignment (divided by row sum) in order to perform normalization (prob. sum = 100%)\n",
    "            if row_sum > 1:\n",
    "                trans[field, state1, :] /= row_sum\n",
    "            else:\n",
    "                trans[field, state1, state1] = 1\n",
    "            \n",
    "        row_sum = np.sum(trans[4, state1, :])\n",
    "        \n",
    "        if row_sum > 1:\n",
    "            trans[4, state1, :] /= row_sum\n",
    "        else:\n",
    "            trans[4, state1, state1] = 1\n",
    "            \n",
    "    return trans\n",
    "\n",
    "trans = trans_prob(states)\n",
    "trans[:1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[1.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.00260417, 0.00260417, 0.00260417, ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         1.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 1.        ]]])"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# create a reward matrix that rewards shortest-possible distances taken by the agent with a bonus\n",
    "def reward_matrix(states, trans):\n",
    "\n",
    "    layout_fields = (2,2)\n",
    "    options_actions = 2\n",
    "    number_fields = 4\n",
    "    options_colors = 3\n",
    "    options_placings = 4\n",
    "\n",
    "    # the 0th tuple element refers to the rows, while the 1st tuple refers to the columns of the layout\n",
    "    col = np.arange(layout_fields[1])\n",
    "    row = np.arange(layout_fields[0])\n",
    "\n",
    "    # set up new array filles with ones across the fields\n",
    "    dist = np.ones(layout_fields)\n",
    "\n",
    "    # transpose distance arrays\n",
    "    dist += col\n",
    "    dist = (dist.T + row).T\n",
    "\n",
    "    dist = dist.flatten()\n",
    "    dist = np.append(dist, 7)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # \n",
    "    for action_number, sparse_matrix in enumerate(trans):\n",
    "        indices = np.where(np.logical_and(sparse_matrix > 0, sparse_matrix < 1))\n",
    "        reward_ratings = np.zeros(sparse_matrix.shape)\n",
    "        reward_ratings[indices] = 10 - dist[action_number]\n",
    "\n",
    "        results.append(reward_ratings)\n",
    "\n",
    "    return results\n",
    "\n",
    "rewards = reward_matrix(states, trans)\n",
    "rewards[:3]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [9., 9., 9., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [8., 8., 8., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [8., 8., 8., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Perform MDP to find optimal (bonus-maximising) policy of the agent\n",
    "\n",
    "policy_best = mdptoolbox.mdp.ValueIteration(transitions=trans, reward=rewards, discount=0.95)\n",
    "policy_best.setVerbose()\n",
    "results = policy_best.run()\n",
    "print(policy_best.policy)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  Iteration\t\tV-variation\n",
      "    1\t\t  6.0\n",
      "    2\t\t  0.29687500000002487\n",
      "    3\t\t  0.10701029459635336\n",
      "    4\t\t  0.0633163226047877\n",
      "    5\t\t  0.031968815284610486\n",
      "    6\t\t  0.016004446243051973\n",
      "    7\t\t  0.00795781280146457\n",
      "    8\t\t  0.003954818209884081\n",
      "    9\t\t  0.001964754670105151\n",
      "    10\t\t  0.0009760481685603395\n",
      "    11\t\t  0.0004848692046479641\n",
      "Iterating stopped, epsilon-optimal policy found.\n",
      "(4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 3, 0, 0, 3, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 3, 0, 0, 3, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 3, 0, 0, 3, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 3, 0, 0, 3, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 3, 0, 0, 3, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 3, 0, 0, 3, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 3, 0, 0, 3, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 3, 0, 0, 3, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 3, 0, 0, 3, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 3, 0, 0, 3, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 3, 0, 0, 3, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 3, 0, 0, 3, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 3, 0, 0, 3, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 3, 0, 0, 3, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 3, 0, 0, 3, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 3, 0, 0, 3, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 3, 0, 0, 3, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 3, 0, 0, 3, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 4, 1, 1, 4, 1, 1, 4, 1, 1, 4, 1, 1, 4, 1, 1, 4, 1, 1, 3, 1, 1, 3, 1, 1, 4, 1, 1, 4, 1, 1, 4, 1, 1, 4, 1, 1, 4, 1, 1, 4, 1, 1, 3, 1, 1, 3, 1, 1, 4, 1, 1, 4, 1, 1, 4, 1, 1, 4, 1, 1, 4, 1, 1, 4, 1, 1, 3, 1, 1, 3, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 4, 1, 1, 4, 1, 1, 4, 1, 1, 4, 1, 1, 4, 1, 1, 4, 1, 1, 3, 1, 1, 3, 1, 1, 4, 1, 1, 4, 1, 1, 4, 1, 1, 4, 1, 1, 4, 1, 1, 4, 1, 1, 3, 1, 1, 3, 1, 1, 4, 1, 1, 4, 1, 1, 4, 1, 1, 4, 1, 1, 4, 1, 1, 4, 1, 1, 3, 1, 1, 3, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 4, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2, 3, 2, 2, 3, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2, 3, 2, 2, 3, 2, 2, 4, 3, 3, 4, 3, 3, 4, 3, 3, 4, 3, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 2, 3, 3, 2, 3, 3, 2, 3, 3, 2, 3, 3, 2, 4, 4, 2, 4, 4, 2, 4, 4, 2, 4, 4, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 3, 3, 1, 3, 3, 1, 3, 3, 1, 3, 3, 1, 4, 4, 1, 4, 4, 1, 4, 4, 1, 4, 4, 1, 3, 3, 1, 3, 3, 1, 3, 3, 1, 3, 3, 1, 4, 4, 1, 4, 4, 1, 4, 4, 1, 4, 4, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 3, 3, 0, 3, 3, 0, 3, 3, 0, 3, 3, 0, 4, 4, 0, 4, 4, 0, 4, 4, 0, 4, 4, 0, 3, 3, 0, 3, 3, 0, 3, 3, 0, 3, 3, 0, 4, 4, 0, 4, 4, 0, 4, 4, 0, 4, 4, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 3, 3, 0, 3, 3, 0, 3, 3, 0, 3, 3, 0, 4, 4, 0, 4, 4, 0, 4, 4, 0, 4, 4, 0, 3, 3, 0, 3, 3, 0, 3, 3, 0, 3, 3, 0, 4, 4, 0, 4, 4, 0, 4, 4, 0, 4, 4)\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}